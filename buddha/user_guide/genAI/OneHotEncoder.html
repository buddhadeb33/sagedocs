
<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>OneHotEncoder &#8212; 3.1</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=30c166bc" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=30c166bc" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=e1ce3931"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script defer data-domain="feature-engine.readthedocs.io" src="https://plausible.io/js/plausible.js"></script>
    <script src="../../_static/js/copybutton.js?v=84772c1c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'user_guide/genAI/OneHotEncoder';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

    <!-- Cookie banner -->
    <style>
        /* Style for the cookie banner */
        #cookie-banner {
            position: fixed;
            bottom: 0;
            right: 0;
            background-color: #ffe4e1; /* Light Pink */
            color: #333;
            padding: 15px;
            max-width: 400px;
            display: none;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            z-index: 1000; /* Set a higher z-index value */
        }

        #cookie-banner p {
        font-size: 16px; /* Font size for the text */
        color: #333 !important; /* Set link color to black */
        line-height: 1.5; /* Increase line height for added spacing between sentences */
        }

        #cookie-banner a {
            color: #333;
            text-decoration: underline;
        }
    </style>

    <div id="cookie-banner">
        <h2 style="font-size: 20px; margin-bottom: 10px;">This site uses cookies</h2>
        <p style="font-size: 16px;">We use cookies to recognize your visits and preferences, to measure the effectiveness of the documentation, and discover how people find us. With your consent, you're helping us make our documentation better. <br><a href="https://www.trainindata.com/p/privacy" target="_blank">Learn More</a>.</p>
        <button id="cookie-accept">Accept</button>
        <button id="cookie-decline">Decline</button>
    </div>

    <script>
        // JavaScript to show the cookie banner and handle the accept button
        document.addEventListener('DOMContentLoaded', function () {
            var cookieBanner = document.getElementById('cookie-banner');
            var acceptButton = document.getElementById('cookie-accept');
            var declineButton = document.getElementById('cookie-decline');

            // Check if the user has already accepted or declined cookies
            var cookiesAccepted = localStorage.getItem('cookiesAccepted');

            if (!cookiesAccepted) {
                cookieBanner.style.display = 'block';

                acceptButton.addEventListener('click', function () {
                    localStorage.setItem('cookiesAccepted', 'true');
                    loadGoogleAnalytics();
                    cookieBanner.style.display = 'none';
                });

                declineButton.addEventListener('click', function () {
                    localStorage.setItem('cookiesAccepted', 'false');
                    cookieBanner.style.display = 'none';
                });
            } else if (cookiesAccepted === 'true') {
                loadGoogleAnalytics();
            }
        });

        function loadGoogleAnalytics() {
            // Load Google Analytics only if consent is given
            var script = document.createElement('script');
            script.async = true;
            script.src = 'https://www.googletagmanager.com/gtag/js?id=G-Z6MPCG673G';
            document.head.appendChild(script);

            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'G-Z6MPCG673G');
        }
    </script>
    <!-- Cookie banner -->


  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/sageops_logo.png" class="logo__image only-light" alt="3.1 - Home"/>
    <script>document.write(`<img src="../../_static/sageops_logo.png" class="logo__image only-dark" alt="3.1 - Home"/>`);</script>
  
  
</a></div>
    
      <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../quickstart/index.html">
                        Quick Start
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index.html">
                        SageOps User Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api_doc/index.html">
                        API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../example_notebooks/index.html">
                        Example Notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../about/index.html">
                        About
                      </a>
                    </li>
                
            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../Support/index.html">
                        Support
                      </a>
                    </li>
                
                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fab fa-github-square fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary" tabindex="0">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item">
<nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../quickstart/index.html">
                        Quick Start
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../index.html">
                        SageOps User Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api_doc/index.html">
                        API
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../example_notebooks/index.html">
                        Example Notebooks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../about/index.html">
                        About
                      </a>
                    </li>
                
            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links-2">
                    More
                </button>
                <ul id="pst-nav-more-links-2" class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../../Support/index.html">
                        Support
                      </a>
                    </li>
                
                </ul>
            </li>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fab fa-github-square fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">OneHotEncoder</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="onehotencoder">
<span id="onehot-encoder"></span><h1>OneHotEncoder<a class="headerlink" href="#onehotencoder" title="Permalink to this heading">#</a></h1>
<p>One-hot encoding is a method used to represent categorical data, where each category
is represented by a binary variable. The binary variable takes the value 1 if the
category is present and 0 otherwise. The binary variables are also known as dummy
variables.</p>
<p>To represent the categorical feature “is-smoker” with categories “Smoker” and
“Non-smoker”, we can generate the dummy variable “Smoker”, which takes 1 if the
person smokes and 0 otherwise. We can also generate the variable “Non-smoker”, which
takes 1 if the person does not smoke and 0 otherwise.</p>
<p>The following table shows a possible one hot encoded representation of the variable
“is smoker”:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>is smoker</p></th>
<th class="head"><p>smoker</p></th>
<th class="head"><p>non-smoker</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>smoker</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>non-smoker</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>non-smoker</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>smoker</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>non-smoker</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>For the categorical variable <strong>Country</strong> with values <strong>England</strong>, <strong>Argentina</strong>, and
<strong>Germany</strong>, we can create three variables called <code class="docutils literal notranslate"><span class="pre">England</span></code>, <code class="docutils literal notranslate"><span class="pre">Argentina</span></code>, and <code class="docutils literal notranslate"><span class="pre">Germany</span></code>.
These variables will take the value of 1 if the observation is England, Argentina, or
Germany, respectively, and 0 otherwise.</p>
<section id="encoding-into-k-vs-k-1-variables">
<h2>Encoding into k vs k-1 variables<a class="headerlink" href="#encoding-into-k-vs-k-1-variables" title="Permalink to this heading">#</a></h2>
<p>A categorical feature with k unique categories can be encoded using k-1 binary variables.
For <code class="docutils literal notranslate"><span class="pre">Smoker</span></code>, k is 2 as it contains two labels (Smoker and Non-Smoker), so we only
need one binary variable (k - 1 = 1) to capture all of the information.</p>
<p>In the following table we see that the dummy variable <code class="docutils literal notranslate"><span class="pre">Smoker</span></code> fully represents the
original categorical values:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>is smoker</p></th>
<th class="head"><p>smoker</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>smoker</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>non-smoker</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>non-smoker</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>smoker</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>non-smoker</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>For the <strong>Country</strong> variable, which has three categories (k=3; England, Argentina, and
Germany), we need two (k - 1 = 2) binary variables to capture all the information. The
variable will be fully represented like this:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Country</p></th>
<th class="head"><p>England</p></th>
<th class="head"><p>Argentina</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>England</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>Argentina</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>Germany</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>As we see in the previous table, if the observation is England, it will show the value 1 in
the <code class="docutils literal notranslate"><span class="pre">England</span></code> variable; if the observation is Argentina, it will show the value 1 in
the <code class="docutils literal notranslate"><span class="pre">Argentina</span></code> variable; and if the observation is Germany, it will show zeroes in
both dummy variables.</p>
<p>Like these, by looking at the values of the k-1 dummies, we can infer the original
categorical value of each observation.</p>
<p>Encoding into k-1 binary variables is well-suited for linear regression models. Linear
models evaluate all features during fit, thus, with k-1 they have all the information
about the original categorical variable.</p>
<p>There are a few occasions in which we may prefer to encode the categorical variables
with k binary variables.</p>
<p>Encode into k dummy variables if training decision trees based models or performing
feature selection. Decision tree based models and many feature selection algorithms
evaluate variables or groups of variables separately. Thus, if encoding into k-1, the
last category will not be examined. In other words, we lose the information contained
in that category.</p>
</section>
<section id="binary-variables">
<h2>Binary variables<a class="headerlink" href="#binary-variables" title="Permalink to this heading">#</a></h2>
<p>When a categorical variable has only 2 categories, like “Smoker” in our previous example,
then encoding into k-1 suits all purposes, because the second dummy variable created
by one hot encoding is completely redundant.</p>
</section>
<section id="encoding-popular-categories">
<h2>Encoding popular categories<a class="headerlink" href="#encoding-popular-categories" title="Permalink to this heading">#</a></h2>
<p>One hot encoding can increase the feature space dramatically, particularly if we have
many categorical features, or the features have high cardinality. To control the feature
space, it is common practice to encode only the most frequent categories in each
categorical variable.</p>
<p>When we encode the most frequent categories, we will create binary variables for each
of these frequent categories, and when the observation has a different, less popular
category, it will have a 0 in all binary variables. See the following example:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>var</p></th>
<th class="head"><p>popular1</p></th>
<th class="head"><p>popular2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>popular1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>popular2</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>popular1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>non-popular</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>popular2</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>less popular</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>unpopular</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>lonely</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>As we see in the previous table, less popular categories are represented as a group by
showing zeroes in all binary variables.</p>
</section>
<section id="id1">
<h2>OneHotEncoder<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>Feature-engine’s <code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code> encodes categorical data as a one-hot numeric
dataframe.</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code> can encode into k or k-1 dummy variables. The behaviour is
specified through the <code class="docutils literal notranslate"><span class="pre">drop_last</span></code> parameter, which can be set to <code class="docutils literal notranslate"><span class="pre">False</span></code> for k, or to
<code class="docutils literal notranslate"><span class="pre">True</span></code> for k-1 dummy variables.</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code> can specifically encode binary variables into k-1 variables
(that is, 1 dummy) while encoding categorical features of higher cardinality into k
dummies. This behaviour is specified by setting the parameter <code class="docutils literal notranslate"><span class="pre">drop_last_binary=True</span></code>.
This will ensure that for every binary variable in the dataset, that is, for every
categorical variable with ONLY 2 categories, only 1 dummy is created. This is recommended,
unless you suspect that the variable could, in principle, take more than 2 values.</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code> can also create binary variables for the <strong>n</strong> most popular
categories, n being determined by the user. For example, if we encode only the 6 more
popular categories, by setting the parameter <code class="docutils literal notranslate"><span class="pre">top_categories=6</span></code>, the transformer will
add binary variables only for the 6 most frequent categories. The most frequent categories
are those with the greatest number of observations. The remaining categories will show
zeroes in each one of the derived dummies. This behaviour is useful when the categorical
variables are highly cardinal to control the expansion of the feature space.</p>
<p><strong>Note</strong></p>
<p>The parameter <code class="docutils literal notranslate"><span class="pre">drop_last</span></code> is ignored when encoding the most popular categories.</p>
</section>
<section id="python-implementation">
<h2>Python implementation<a class="headerlink" href="#python-implementation" title="Permalink to this heading">#</a></h2>
<p>Let’s look at an example of one hot encoding, using Feature-engine’s  <code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code>
utilizing the Titanic Dataset.</p>
<p>We’ll start by importing the libraries, functions and classes, and loading the data into
a pandas dataframe and dividing it into a training and a testing set:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">feature_engine.datasets</span> <span class="kn">import</span> <span class="n">load_titanic</span>
<span class="kn">from</span> <span class="nn">feature_engine.encoding</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_titanic</span><span class="p">(</span>
    <span class="n">return_X_y_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">handle_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">predictors_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">cabin</span><span class="o">=</span><span class="s2">&quot;letter_only&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<p>We see the first 5 rows of the training data below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>      <span class="n">pclass</span>     <span class="n">sex</span>        <span class="n">age</span>  <span class="n">sibsp</span>  <span class="n">parch</span>     <span class="n">fare</span> <span class="n">cabin</span> <span class="n">embarked</span>
<span class="mi">501</span>        <span class="mi">2</span>  <span class="n">female</span>  <span class="mf">13.000000</span>      <span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">19.5000</span>     <span class="n">M</span>        <span class="n">S</span>
<span class="mi">588</span>        <span class="mi">2</span>  <span class="n">female</span>   <span class="mf">4.000000</span>      <span class="mi">1</span>      <span class="mi">1</span>  <span class="mf">23.0000</span>     <span class="n">M</span>        <span class="n">S</span>
<span class="mi">402</span>        <span class="mi">2</span>  <span class="n">female</span>  <span class="mf">30.000000</span>      <span class="mi">1</span>      <span class="mi">0</span>  <span class="mf">13.8583</span>     <span class="n">M</span>        <span class="n">C</span>
<span class="mi">1193</span>       <span class="mi">3</span>    <span class="n">male</span>  <span class="mf">29.881135</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>     <span class="n">M</span>        <span class="n">Q</span>
<span class="mi">686</span>        <span class="mi">3</span>  <span class="n">female</span>  <span class="mf">22.000000</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>     <span class="n">M</span>        <span class="n">Q</span>
</pre></div>
</div>
<p>Let’s explore the cardinality of 4 of the categorical features:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">[[</span><span class="s1">&#39;sex&#39;</span><span class="p">,</span> <span class="s1">&#39;pclass&#39;</span><span class="p">,</span> <span class="s1">&#39;cabin&#39;</span><span class="p">,</span> <span class="s1">&#39;embarked&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sex</span>         <span class="mi">2</span>
<span class="n">pclass</span>      <span class="mi">3</span>
<span class="n">cabin</span>       <span class="mi">9</span>
<span class="n">embarked</span>    <span class="mi">4</span>
<span class="n">dtype</span><span class="p">:</span> <span class="n">int64</span>
</pre></div>
</div>
<p>We see that the variable sex has 2 categories, pclass has 3 categories, the variable
cabin has 9 categories, and the variable embarked has 4 categories.</p>
<p>Let’s now set up the OneHotEncoder to encode 2 of the categorical variables into k-1 dummy
variables:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span>
    <span class="n">variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cabin&#39;</span><span class="p">,</span> <span class="s1">&#39;embarked&#39;</span><span class="p">],</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">fit()</span></code> the encoder learns the categories of the variables, which are stored in the
attribute <code class="docutils literal notranslate"><span class="pre">encoder_dict_</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span><span class="o">.</span><span class="n">encoder_dict_</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;cabin&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">],</span>
 <span class="s1">&#39;embarked&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;Q&#39;</span><span class="p">]}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">encoder_dict_</span></code> contains the categories that will be represented by dummy variables
for each categorical variable.</p>
<p>With transform, we go ahead and encode the variables. Note that by default, the
<code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code> drops the original categorical variables, which are now
represented by the one-hot array.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_t</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">test_t</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_t</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<p>Below we see the one hot dummy variables added to the dataset and the original variables
are no longer in the dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>      <span class="n">pclass</span>     <span class="n">sex</span>        <span class="n">age</span>  <span class="n">sibsp</span>  <span class="n">parch</span>     <span class="n">fare</span>  <span class="n">cabin_M</span>  <span class="n">cabin_E</span>  \
<span class="mi">501</span>        <span class="mi">2</span>  <span class="n">female</span>  <span class="mf">13.000000</span>      <span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">19.5000</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">588</span>        <span class="mi">2</span>  <span class="n">female</span>   <span class="mf">4.000000</span>      <span class="mi">1</span>      <span class="mi">1</span>  <span class="mf">23.0000</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">402</span>        <span class="mi">2</span>  <span class="n">female</span>  <span class="mf">30.000000</span>      <span class="mi">1</span>      <span class="mi">0</span>  <span class="mf">13.8583</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">1193</span>       <span class="mi">3</span>    <span class="n">male</span>  <span class="mf">29.881135</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">686</span>        <span class="mi">3</span>  <span class="n">female</span>  <span class="mf">22.000000</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>        <span class="mi">1</span>        <span class="mi">0</span>

      <span class="n">cabin_C</span>  <span class="n">cabin_D</span>  <span class="n">cabin_B</span>  <span class="n">cabin_A</span>  <span class="n">cabin_F</span>  <span class="n">cabin_T</span>  <span class="n">embarked_S</span>  \
<span class="mi">501</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">1</span>
<span class="mi">588</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">1</span>
<span class="mi">402</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">1193</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">686</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">0</span>

      <span class="n">embarked_C</span>  <span class="n">embarked_Q</span>
<span class="mi">501</span>            <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">588</span>            <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">402</span>            <span class="mi">1</span>           <span class="mi">0</span>
<span class="mi">1193</span>           <span class="mi">0</span>           <span class="mi">1</span>
<span class="mi">686</span>            <span class="mi">0</span>           <span class="mi">1</span>
</pre></div>
</div>
<section id="finding-categorical-variables-automatically">
<h3>Finding categorical variables automatically<a class="headerlink" href="#finding-categorical-variables-automatically" title="Permalink to this heading">#</a></h3>
<p>Feature-engine’s <code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code> can automatically find and encode all
categorical features in the pandas dataframe. Let’s show that with an example.</p>
<p>Let’s set up the OneHotEncoder to find and encode all categorical features:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span>
    <span class="n">variables</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>With fit, the encoder finds the categorical features and identifies it’s unique
categories. We can find the categorical variables like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span><span class="o">.</span><span class="n">variables_</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">,</span> <span class="s1">&#39;cabin&#39;</span><span class="p">,</span> <span class="s1">&#39;embarked&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>And we can identify the unique categories for each variables like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span><span class="o">.</span><span class="n">encoder_dict_</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;sex&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">],</span>
 <span class="s1">&#39;cabin&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">],</span>
 <span class="s1">&#39;embarked&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;Q&#39;</span><span class="p">]}</span>
</pre></div>
</div>
<p>We can now encode the categorical variables:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_t</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">test_t</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_t</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<p>And here we see the resulting dataframe:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>      <span class="n">pclass</span>        <span class="n">age</span>  <span class="n">sibsp</span>  <span class="n">parch</span>     <span class="n">fare</span>  <span class="n">sex_female</span>  <span class="n">cabin_M</span>  <span class="n">cabin_E</span>  \
<span class="mi">501</span>        <span class="mi">2</span>  <span class="mf">13.000000</span>      <span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">19.5000</span>           <span class="mi">1</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">588</span>        <span class="mi">2</span>   <span class="mf">4.000000</span>      <span class="mi">1</span>      <span class="mi">1</span>  <span class="mf">23.0000</span>           <span class="mi">1</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">402</span>        <span class="mi">2</span>  <span class="mf">30.000000</span>      <span class="mi">1</span>      <span class="mi">0</span>  <span class="mf">13.8583</span>           <span class="mi">1</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">1193</span>       <span class="mi">3</span>  <span class="mf">29.881135</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>           <span class="mi">0</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">686</span>        <span class="mi">3</span>  <span class="mf">22.000000</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>           <span class="mi">1</span>        <span class="mi">1</span>        <span class="mi">0</span>

      <span class="n">cabin_C</span>  <span class="n">cabin_D</span>  <span class="n">cabin_B</span>  <span class="n">cabin_A</span>  <span class="n">cabin_F</span>  <span class="n">cabin_T</span>  <span class="n">embarked_S</span>  \
<span class="mi">501</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">1</span>
<span class="mi">588</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">1</span>
<span class="mi">402</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">1193</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">686</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>           <span class="mi">0</span>

      <span class="n">embarked_C</span>  <span class="n">embarked_Q</span>
<span class="mi">501</span>            <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">588</span>            <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">402</span>            <span class="mi">1</span>           <span class="mi">0</span>
<span class="mi">1193</span>           <span class="mi">0</span>           <span class="mi">1</span>
<span class="mi">686</span>            <span class="mi">0</span>           <span class="mi">1</span>
</pre></div>
</div>
</section>
</section>
<section id="encoding-variables-of-type-numeric">
<h2>Encoding variables of type numeric<a class="headerlink" href="#encoding-variables-of-type-numeric" title="Permalink to this heading">#</a></h2>
<p>By default, Feature-engine’s <code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code> will only encode categorical
features. If you attempt to encode a variable of numeric dtype, it will raise an error.
To avoid this error, you can instruct the encoder to ignore the data type format as
follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span>
    <span class="n">variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pclass&#39;</span><span class="p">],</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">ignore_format</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">train_t</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">test_t</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_t</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<p>Note that pclass had numeric values instead of strings, and it was one hot encoded by
the transformer into 2 dummies:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>         <span class="n">sex</span>        <span class="n">age</span>  <span class="n">sibsp</span>  <span class="n">parch</span>     <span class="n">fare</span> <span class="n">cabin</span> <span class="n">embarked</span>  <span class="n">pclass_2</span>  \
<span class="mi">501</span>   <span class="n">female</span>  <span class="mf">13.000000</span>      <span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">19.5000</span>     <span class="n">M</span>        <span class="n">S</span>         <span class="mi">1</span>
<span class="mi">588</span>   <span class="n">female</span>   <span class="mf">4.000000</span>      <span class="mi">1</span>      <span class="mi">1</span>  <span class="mf">23.0000</span>     <span class="n">M</span>        <span class="n">S</span>         <span class="mi">1</span>
<span class="mi">402</span>   <span class="n">female</span>  <span class="mf">30.000000</span>      <span class="mi">1</span>      <span class="mi">0</span>  <span class="mf">13.8583</span>     <span class="n">M</span>        <span class="n">C</span>         <span class="mi">1</span>
<span class="mi">1193</span>    <span class="n">male</span>  <span class="mf">29.881135</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>     <span class="n">M</span>        <span class="n">Q</span>         <span class="mi">0</span>
<span class="mi">686</span>   <span class="n">female</span>  <span class="mf">22.000000</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>     <span class="n">M</span>        <span class="n">Q</span>         <span class="mi">0</span>

      <span class="n">pclass_3</span>
<span class="mi">501</span>          <span class="mi">0</span>
<span class="mi">588</span>          <span class="mi">0</span>
<span class="mi">402</span>          <span class="mi">0</span>
<span class="mi">1193</span>         <span class="mi">1</span>
<span class="mi">686</span>          <span class="mi">1</span>
</pre></div>
</div>
<section id="encoding-binary-variables-into-1-dummy">
<h3>Encoding binary variables into 1 dummy<a class="headerlink" href="#encoding-binary-variables-into-1-dummy" title="Permalink to this heading">#</a></h3>
<p>With Feature-engine’s <code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code> we can encode all categorical variables
into k dummies and the binary variables into k-1 by setting the encoder as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span>
    <span class="n">variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">,</span> <span class="s1">&#39;cabin&#39;</span><span class="p">,</span><span class="s1">&#39;embarked&#39;</span><span class="p">],</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">drop_last_binary</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">train_t</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">test_t</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_t</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<p>As we see in the following input, for the variable sex, we have only have 1 dummy,
and for all the rest we have k dummies:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>      <span class="n">pclass</span>        <span class="n">age</span>  <span class="n">sibsp</span>  <span class="n">parch</span>     <span class="n">fare</span>  <span class="n">sex_female</span>  <span class="n">cabin_M</span>  <span class="n">cabin_E</span>  \
<span class="mi">501</span>        <span class="mi">2</span>  <span class="mf">13.000000</span>      <span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">19.5000</span>           <span class="mi">1</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">588</span>        <span class="mi">2</span>   <span class="mf">4.000000</span>      <span class="mi">1</span>      <span class="mi">1</span>  <span class="mf">23.0000</span>           <span class="mi">1</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">402</span>        <span class="mi">2</span>  <span class="mf">30.000000</span>      <span class="mi">1</span>      <span class="mi">0</span>  <span class="mf">13.8583</span>           <span class="mi">1</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">1193</span>       <span class="mi">3</span>  <span class="mf">29.881135</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>           <span class="mi">0</span>        <span class="mi">1</span>        <span class="mi">0</span>
<span class="mi">686</span>        <span class="mi">3</span>  <span class="mf">22.000000</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>           <span class="mi">1</span>        <span class="mi">1</span>        <span class="mi">0</span>

      <span class="n">cabin_C</span>  <span class="n">cabin_D</span>  <span class="n">cabin_B</span>  <span class="n">cabin_A</span>  <span class="n">cabin_F</span>  <span class="n">cabin_T</span>  <span class="n">cabin_G</span>  \
<span class="mi">501</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>
<span class="mi">588</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>
<span class="mi">402</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>
<span class="mi">1193</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>
<span class="mi">686</span>         <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>        <span class="mi">0</span>

      <span class="n">embarked_S</span>  <span class="n">embarked_C</span>  <span class="n">embarked_Q</span>  <span class="n">embarked_Missing</span>
<span class="mi">501</span>            <span class="mi">1</span>           <span class="mi">0</span>           <span class="mi">0</span>                 <span class="mi">0</span>
<span class="mi">588</span>            <span class="mi">1</span>           <span class="mi">0</span>           <span class="mi">0</span>                 <span class="mi">0</span>
<span class="mi">402</span>            <span class="mi">0</span>           <span class="mi">1</span>           <span class="mi">0</span>                 <span class="mi">0</span>
<span class="mi">1193</span>           <span class="mi">0</span>           <span class="mi">0</span>           <span class="mi">1</span>                 <span class="mi">0</span>
</pre></div>
</div>
</section>
<section id="encoding-frequent-categories">
<h3>Encoding frequent categories<a class="headerlink" href="#encoding-frequent-categories" title="Permalink to this heading">#</a></h3>
<p>If the categorical variables are highly cardinal, we may end up with very big datasets
after one hot encoding. In addition, if some of these variables are fairly constant or
fairly similar, we may end up with one hot encoded features that are highly correlated,
if not identical. To avoid this behaviour, we can encode only the most frequent categories.</p>
<p>To encode the 2 most frequent categories of each categorical column, we set up the
transformer as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span>
    <span class="n">top_categories</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">variables</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pclass&#39;</span><span class="p">,</span> <span class="s1">&#39;cabin&#39;</span><span class="p">,</span> <span class="s1">&#39;embarked&#39;</span><span class="p">],</span>
    <span class="n">ignore_format</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">train_t</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">test_t</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_t</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<p>As we see in the resulting dataframe, we created only 2 dummies per variable:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>         <span class="n">sex</span>        <span class="n">age</span>  <span class="n">sibsp</span>  <span class="n">parch</span>     <span class="n">fare</span>  <span class="n">pclass_3</span>  <span class="n">pclass_1</span>  <span class="n">cabin_M</span>  \
<span class="mi">501</span>   <span class="n">female</span>  <span class="mf">13.000000</span>      <span class="mi">0</span>      <span class="mi">1</span>  <span class="mf">19.5000</span>         <span class="mi">0</span>         <span class="mi">0</span>        <span class="mi">1</span>
<span class="mi">588</span>   <span class="n">female</span>   <span class="mf">4.000000</span>      <span class="mi">1</span>      <span class="mi">1</span>  <span class="mf">23.0000</span>         <span class="mi">0</span>         <span class="mi">0</span>        <span class="mi">1</span>
<span class="mi">402</span>   <span class="n">female</span>  <span class="mf">30.000000</span>      <span class="mi">1</span>      <span class="mi">0</span>  <span class="mf">13.8583</span>         <span class="mi">0</span>         <span class="mi">0</span>        <span class="mi">1</span>
<span class="mi">1193</span>    <span class="n">male</span>  <span class="mf">29.881135</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>         <span class="mi">1</span>         <span class="mi">0</span>        <span class="mi">1</span>
<span class="mi">686</span>   <span class="n">female</span>  <span class="mf">22.000000</span>      <span class="mi">0</span>      <span class="mi">0</span>   <span class="mf">7.7250</span>         <span class="mi">1</span>         <span class="mi">0</span>        <span class="mi">1</span>

      <span class="n">cabin_C</span>  <span class="n">embarked_S</span>  <span class="n">embarked_C</span>
<span class="mi">501</span>         <span class="mi">0</span>           <span class="mi">1</span>           <span class="mi">0</span>
<span class="mi">588</span>         <span class="mi">0</span>           <span class="mi">1</span>           <span class="mi">0</span>
<span class="mi">402</span>         <span class="mi">0</span>           <span class="mi">0</span>           <span class="mi">1</span>
<span class="mi">1193</span>        <span class="mi">0</span>           <span class="mi">0</span>           <span class="mi">0</span>
<span class="mi">686</span>         <span class="mi">0</span>           <span class="mi">0</span>           <span class="mi">0</span>
</pre></div>
</div>
<p>Finally, if we want to obtain the column names in the resulting dataframe we can do the
following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
</pre></div>
</div>
<p>We see the names of the columns below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">,</span>
 <span class="s1">&#39;age&#39;</span><span class="p">,</span>
 <span class="s1">&#39;sibsp&#39;</span><span class="p">,</span>
 <span class="s1">&#39;parch&#39;</span><span class="p">,</span>
 <span class="s1">&#39;fare&#39;</span><span class="p">,</span>
 <span class="s1">&#39;pclass_3&#39;</span><span class="p">,</span>
 <span class="s1">&#39;pclass_1&#39;</span><span class="p">,</span>
 <span class="s1">&#39;cabin_M&#39;</span><span class="p">,</span>
 <span class="s1">&#39;cabin_C&#39;</span><span class="p">,</span>
 <span class="s1">&#39;embarked_S&#39;</span><span class="p">,</span>
 <span class="s1">&#39;embarked_C&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
</section>
<section id="considerations">
<h2>Considerations<a class="headerlink" href="#considerations" title="Permalink to this heading">#</a></h2>
<p>Encoding categorical variables into k dummies, will handle unknown categories automatically.
Those features not seen during training will show zeroes in all dummies.</p>
<p>Encoding categorical features into k-1 dummies, will cause unseen data to be treated as
the category that is dropped.</p>
<p>Encoding the top categories will make unseen categories part of the group of less popular
categories.</p>
<p>If you add a big number of dummy variables to your data, many may be identical or highly
correlated. Consider dropping identical and correlated features with the transformers
from the <a class="reference internal" href="../selection/index.html#selection-user-guide"><span class="std std-ref">selection module</span></a>.</p>
<p>For alternative encoding methods used in data science check the <code class="xref py py-class docutils literal notranslate"><span class="pre">OrdinalEncoder()</span></code>
and other encoders included in the <a class="reference internal" href="index.html#encoding-user-guide"><span class="std std-ref">encoding module</span></a>.</p>
</section>
<section id="tutorials-books-and-courses">
<h2>Tutorials, books and courses<a class="headerlink" href="#tutorials-books-and-courses" title="Permalink to this heading">#</a></h2>
<p>For more details into <code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder()</span></code>’s functionality visit:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://nbviewer.org/github/feature-engine/feature-engine-examples/blob/main/encoding/OneHotEncoder.ipynb">Jupyter notebook</a></p></li>
</ul>
<p>For tutorials about this and other data preprocessing methods check out our online course:</p>
<figure class="align-center align-left" id="id2">
<a class="reference external image-reference" href="https://www.trainindata.com/p/feature-engineering-for-machine-learning"><img alt="../../_images/feml.png" src="../../_images/feml.png" style="width: 300px;" /></a>
<figcaption>
<p><span class="caption-text">Feature Engineering for Machine Learning</span><a class="headerlink" href="#id2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p>Or read our book:</p>
<figure class="align-center align-left" id="id3">
<a class="reference external image-reference" href="https://www.packtpub.com/en-us/product/python-feature-engineering-cookbook-9781835883587"><img alt="../../_images/cookbook.png" src="../../_images/cookbook.png" style="width: 200px;" /></a>
<figcaption>
<p><span class="caption-text">Python Feature Engineering Cookbook</span><a class="headerlink" href="#id3" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p>Both our book and course are suitable for beginners and more advanced data scientists
alike. By purchasing them you are supporting Sole, the main developer of Feature-engine.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">

  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#encoding-into-k-vs-k-1-variables">Encoding into k vs k-1 variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#binary-variables">Binary variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#encoding-popular-categories">Encoding popular categories</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">OneHotEncoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#python-implementation">Python implementation</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-categorical-variables-automatically">Finding categorical variables automatically</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#encoding-variables-of-type-numeric">Encoding variables of type numeric</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#encoding-binary-variables-into-1-dummy">Encoding binary variables into 1 dummy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#encoding-frequent-categories">Encoding frequent categories</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#considerations">Considerations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tutorials-books-and-courses">Tutorials, books and courses</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../../_sources/user_guide/genAI/OneHotEncoder.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.1.2.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.14.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>